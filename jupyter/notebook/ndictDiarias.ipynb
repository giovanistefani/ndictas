{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "import os.path\n",
    "import csv\n",
    "import petl as etl\n",
    "from collections import OrderedDict\n",
    "from azure.storage.blob import BlobServiceClient, ContainerClient, BlobClient, BlobBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_name='datalake2dictas'\n",
    "account_key='wlxJHcWvtVhPpL/zs6l+F1bJGKZnJ4HppZcVyh+ns32oH46E3dY/HBLau3V6um9hv+KZf/3mXEAL5nHD41X3jg=='\n",
    "container_from = 'transient'\n",
    "container_to = 'raw'\n",
    "upload_file = '/opt/jupyter_etl_dictas/datalake/transient/beneficiario/beneficiarios_atualizado.csv'\n",
    "_LOCALDIR = '/opt/jupyter_etl_dictas/datalake/transient'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_transient = ContainerClient(account_url=f\"https://{account_name}.blob.core.windows.net/\",container_name=container_from, credential=account_key)\n",
    "cc_raw = ContainerClient(account_url=f\"https://{account_name}.blob.core.windows.net/\",container_name=container_to, credential=account_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_TEMP_FILE='datalake/temp'\n",
    "_METADADOS='metadado/list.csv'\n",
    "_SOURCE='17'\n",
    "_PROC_FILES='datalake/proc'\n",
    "_NM_ARQ = 'DIARIAS.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carrega blob Diarias\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verifica Arquivo no Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BENEFICIARIO.csv\n",
      "\n",
      "CONSULTAS.csv\n",
      "\n",
      "DIARIAS.csv\n",
      "\n",
      "EMPRESA.csv\n",
      "\n",
      "PRESTADORES.csv\n",
      "\n",
      "SERVICOS.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "blob_list = cc_transient.list_blobs()\n",
    "for blob in blob_list:\n",
    "    print(blob.name + '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Faz Download para diretório local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (f'{_PROC_FILES}/{_SOURCE}/{_NM_ARQ}', 'wb') as data_from :\n",
    "    data_from.write(cc_transient.get_blob_client(_NM_ARQ).download_blob ().readall ())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carrega dados para transformação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class='petl'>\n",
       "<thead>\n",
       "<tr>\n",
       "<th>﻿fk_servico</th>\n",
       "<th>tipo</th>\n",
       "<th>grupo_dictas</th>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td>18000030\t</td>\n",
       "<td>Diarias, taxas e gases medicinais\t</td>\n",
       "<td>DIARIAS</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>18000031\t</td>\n",
       "<td>Diarias, taxas e gases medicinais\t</td>\n",
       "<td>DIARIAS</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>18000032\t</td>\n",
       "<td>Diarias, taxas e gases medicinais\t</td>\n",
       "<td>DIARIAS</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>18000033\t</td>\n",
       "<td>Diarias, taxas e gases medicinais\t</td>\n",
       "<td>DIARIAS</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>18000034\t</td>\n",
       "<td>Diarias, taxas e gases medicinais\t</td>\n",
       "<td>DIARIAS</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "<p><strong>...</strong></p>"
      ],
      "text/plain": [
       "+--------------+---------------------------------------+--------------+\n",
       "| ﻿fk_servico  | tipo                                  | grupo_dictas |\n",
       "+==============+=======================================+==============+\n",
       "| '18000030\\t' | 'Diarias, taxas e gases medicinais\\t' | 'DIARIAS'    |\n",
       "+--------------+---------------------------------------+--------------+\n",
       "| '18000031\\t' | 'Diarias, taxas e gases medicinais\\t' | 'DIARIAS'    |\n",
       "+--------------+---------------------------------------+--------------+\n",
       "| '18000032\\t' | 'Diarias, taxas e gases medicinais\\t' | 'DIARIAS'    |\n",
       "+--------------+---------------------------------------+--------------+\n",
       "| '18000033\\t' | 'Diarias, taxas e gases medicinais\\t' | 'DIARIAS'    |\n",
       "+--------------+---------------------------------------+--------------+\n",
       "| '18000034\\t' | 'Diarias, taxas e gases medicinais\\t' | 'DIARIAS'    |\n",
       "+--------------+---------------------------------------+--------------+\n",
       "..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = etl.fromcsv(f'{_PROC_FILES}/{_SOURCE}/{_NM_ARQ}', delimiter='|')\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class='petl'>\n",
       "<thead>\n",
       "<tr>\n",
       "<th>fk_servico</th>\n",
       "<th>tipo</th>\n",
       "<th>grupo_dictas</th>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td>18000030</td>\n",
       "<td>Diarias, taxas e gases medicinais</td>\n",
       "<td>DIARIAS</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>18000031</td>\n",
       "<td>Diarias, taxas e gases medicinais</td>\n",
       "<td>DIARIAS</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>18000032</td>\n",
       "<td>Diarias, taxas e gases medicinais</td>\n",
       "<td>DIARIAS</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>18000033</td>\n",
       "<td>Diarias, taxas e gases medicinais</td>\n",
       "<td>DIARIAS</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>18000034</td>\n",
       "<td>Diarias, taxas e gases medicinais</td>\n",
       "<td>DIARIAS</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "<p><strong>...</strong></p>"
      ],
      "text/plain": [
       "+------------+-------------------------------------+--------------+\n",
       "| fk_servico | tipo                                | grupo_dictas |\n",
       "+============+=====================================+==============+\n",
       "| '18000030' | 'Diarias, taxas e gases medicinais' | 'DIARIAS'    |\n",
       "+------------+-------------------------------------+--------------+\n",
       "| '18000031' | 'Diarias, taxas e gases medicinais' | 'DIARIAS'    |\n",
       "+------------+-------------------------------------+--------------+\n",
       "| '18000032' | 'Diarias, taxas e gases medicinais' | 'DIARIAS'    |\n",
       "+------------+-------------------------------------+--------------+\n",
       "| '18000033' | 'Diarias, taxas e gases medicinais' | 'DIARIAS'    |\n",
       "+------------+-------------------------------------+--------------+\n",
       "| '18000034' | 'Diarias, taxas e gases medicinais' | 'DIARIAS'    |\n",
       "+------------+-------------------------------------+--------------+\n",
       "..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transforma sexo e tira os espaços vazios e substitui string 'NULL' por ''\n",
    "def rowmapper(row):\n",
    "    #strnull = {'NULL':''}\n",
    "    return [row[0].strip(),\n",
    "            row[1].strip(),\n",
    "            row[2].strip(),\n",
    "            ]\n",
    "\n",
    "table1 = etl.rowmap(table, rowmapper,\n",
    "                    header=['fk_servico','tipo','grupo_dictas'\n",
    "                           ])\n",
    "table1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add fk_empresa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "table2 = etl.addfields(table1,[('cd_empresa',_SOURCE)])\n",
    "#table2\n",
    "etl.tocsv(table2, f'{_PROC_FILES}/{_SOURCE}/t{_NM_ARQ}', delimiter='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tudo carregado\n"
     ]
    }
   ],
   "source": [
    "upload_file=f'{_PROC_FILES}/{_SOURCE}/t{_NM_ARQ}'\n",
    "#print(upload_file)\n",
    "try:\n",
    "    with open (upload_file, \"rb\") as data :\n",
    "        #print(data)\n",
    "        cc_raw.upload_blob(_NM_ARQ, data, overwrite = True)\n",
    "finally:\n",
    "    print(\"Tudo carregado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verifica se arquivo está no Blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BENEFICIARIO.csv\n",
      "\n",
      "CONSULTAS.csv\n",
      "\n",
      "DIARIAS.csv\n",
      "\n",
      "EMPRESA.csv\n",
      "\n",
      "PRESTADORES.csv\n",
      "\n",
      "SERVICOS.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "blob_list = cc_raw.list_blobs()\n",
    "for blob in blob_list:\n",
    "    print(blob.name + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
