{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "import os.path\n",
    "import csv\n",
    "import petl as etl\n",
    "from collections import OrderedDict\n",
    "from azure.storage.blob import BlobServiceClient, ContainerClient, BlobClient, BlobBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_name='datalake2dictas'\n",
    "account_key='wlxJHcWvtVhPpL/zs6l+F1bJGKZnJ4HppZcVyh+ns32oH46E3dY/HBLau3V6um9hv+KZf/3mXEAL5nHD41X3jg=='\n",
    "container_from = 'transient'\n",
    "container_to = 'raw'\n",
    "upload_file = '/opt/jupyter_etl_dictas/datalake/transient/beneficiario/beneficiarios_atualizado.csv'\n",
    "_LOCALDIR = '/opt/jupyter_etl_dictas/datalake/transient'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_transient = ContainerClient(account_url=f\"https://{account_name}.blob.core.windows.net/\",container_name=container_from, credential=account_key)\n",
    "cc_raw = ContainerClient(account_url=f\"https://{account_name}.blob.core.windows.net/\",container_name=container_to, credential=account_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_TEMP_FILE='datalake/temp'\n",
    "_METADADOS='metadado/list.csv'\n",
    "_SOURCE='17'\n",
    "_PROC_FILES='datalake/proc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lista Blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "List blobs in the container\n",
      "BENEFICIARIO.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List the blobs in the container.\n",
    "print(\"\\nList blobs in the container\")\n",
    "blob_list = cc_transient.list_blobs()\n",
    "for blob in blob_list:\n",
    "    print(blob.name + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Busca lista de arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BENEFICIARIO.csv\n",
      "PRESTADOR.csv\n",
      "EMPRESA.csv\n",
      "SERVICO.csv\n",
      "VIDAS.csv\n",
      "RECEITA.csv\n",
      "CUSTO.csv\n"
     ]
    }
   ],
   "source": [
    "with open(_METADADOS, newline='') as lista:\n",
    "    reader = csv.DictReader(lista)\n",
    "    for nm_file in reader:\n",
    "        print(nm_file['ARQUIVOS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Teste de carga blog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo BENEFICIARIO.csv carregado\n",
      "Arquivo PRESTADOR.csv não encontrado\n",
      "Arquivo EMPRESA.csv não encontrado\n",
      "Arquivo SERVICO.csv não encontrado\n",
      "Arquivo VIDAS.csv não encontrado\n",
      "Arquivo RECEITA.csv não encontrado\n",
      "Arquivo CUSTO.csv não encontrado\n",
      "Tudo carregado\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(_METADADOS, newline='') as lista:\n",
    "        reader = csv.DictReader(lista)\n",
    "        for nm_file in reader:\n",
    "            file = nm_file['ARQUIVOS']\n",
    "            blob = cc_transient.get_blob_client(file)\n",
    "            upload_file = f'{_TEMP_FILE}/{_SOURCE}/{file}'\n",
    "            t_arq = os.path.isfile(upload_file)\n",
    "            if t_arq == True:\n",
    "                 with open (upload_file, \"rb\") as data :\n",
    "                    blob.upload_blob(data, overwrite = True)\n",
    "                    print(\"Arquivo \"+ file +\" carregado\")\n",
    "            else:\n",
    "                print(\"Arquivo \"+ file +\" não encontrado\")\n",
    "        \n",
    "finally:\n",
    "    print(\"Tudo carregado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carrega blob Beneficiario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verifica Arquivo no Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BENEFICIARIO.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "blob_list = cc_transient.list_blobs()\n",
    "for blob in blob_list:\n",
    "    print(blob.name + '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Faz Download para diretório local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_list = cc_transient.list_blobs()\n",
    "for blob in blob_list:\n",
    "    #print(blob.name + '\\n')\n",
    "    nm_arq=blob.name\n",
    "    #print(nm_arq)\n",
    "    with open (f'{_PROC_FILES}/{_SOURCE}/{nm_arq}', 'wb') as data_from :\n",
    "        data_from.write(cc_transient.get_blob_client(nm_arq).download_blob ().readall ())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carrega dados para transformação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = etl.fromcsv(f'{_PROC_FILES}/{_SOURCE}/{nm_arq}', delimiter='|')\n",
    "#table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforma sexo e tira os espaços vazios e substitui string 'NULL' por ''\n",
    "def rowmapper(row):\n",
    "    transmf = {'MASCULINO': 'M', 'FEMININO': 'F'}\n",
    "    strnull = {'NULL':''}\n",
    "    return [row[0].strip(),row[1].strip(),row[2].strip(),row[3].strip(),\n",
    "            row[4].strip(),row[5].strip(),row[6].strip(),row[7].strip(),\n",
    "            row[8].strip(),\n",
    "            strnull[row['copart_percentual'].strip()] if row['copart_percentual'].strip() in strnull else row['copart_percentual'].strip(),\n",
    "            strnull[row['limite_copart'].strip()] if row['limite_copart'].strip() in strnull else row['limite_copart'].strip(),\n",
    "            row[11].strip(),\n",
    "            row[12].strip(),row[13].strip(),row[14].strip(),\n",
    "            strnull[row['dt_exclusao'].strip()] if row['dt_exclusao'].strip() in strnull else row['dt_exclusao'].strip(),\n",
    "            row[16],\n",
    "            transmf[row['sexo'].strip()] if row['sexo'].strip() in transmf else None,\n",
    "            row[18].strip(),row[19].strip(),row[20].strip(),row[21].strip(),\n",
    "            row[22].strip(),row[23].strip(),row[24].strip(),row[25].strip(),\n",
    "            row[26].strip(),row[27].strip(),row[28].strip(),row[29].strip()\n",
    "           ]\n",
    "\n",
    "table1 = etl.rowmap(table, rowmapper,\n",
    "                    header=['pk_beneficiario','nr_beneficiario','nr_beneficiario_tit','fk_empresa',\n",
    "                            'nome','cpf','dt_nascimento','cod_plano',\n",
    "                            'descricao_plano','copart_percentual','limite_copart','tipo_acomodacao',\n",
    "                            'abrangencia_plano','grau_dependencia','dt_inclusao','dt_exclusao',\n",
    "                            'nome_mae', 'sexo','tipo_contrato','endereco','bairro','cidade',\n",
    "                            'uf','cep','tipo_cliente','nr_cartaonacionalsaude',\n",
    "                            'plano_regulamentado','descricao_entidade','tipo_pessoa','acao_judicial'\n",
    "                           ])\n",
    "#table1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add fk_empresa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "table2 = etl.addfields(table1,[('cd_empresa',_SOURCE)])\n",
    "etl.tocsv(table2, f'{_PROC_FILES}/{_SOURCE}/t{nm_arq}', delimiter='|')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
