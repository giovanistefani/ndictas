{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse notebook faz a segunda análise dos dados da CEMIG."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importações, configurações e funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import MetaData\n",
    "from sqlalchemy import exc\n",
    "from io import StringIO\n",
    "import table_columns\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SCHEMA=dictasstage\n"
     ]
    }
   ],
   "source": [
    "# engine = create_engine('postgresql+psycopg2://{}:{}@{}:{}/{}'.format(\n",
    "#     'dictasstage',\n",
    "#     'IfZSK740mMNHrUbA',\n",
    "#     '40.87.86.193',\n",
    "#     '5432' ,\n",
    "#     'dictasstage'\n",
    "# ))\n",
    "\n",
    "# %env SCHEMA = dictasstage\n",
    "# operadora = 17\n",
    "\n",
    "# def load_to_db_append(df):\n",
    "#     df.to_sql('stg_op{}_{}'.format(operadora, tabela),\n",
    "#           con=engine,\n",
    "#           schema=os.getenv('SCHEMA'),\n",
    "#           if_exists='append',\n",
    "#           index=False,\n",
    "#           chunksize=10000,\n",
    "#           method='multi'\n",
    "#          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine = create_engine('postgresql+psycopg2://{}:{}@{}:{}/{}'.format(\n",
    "#     'bunch',\n",
    "#     'Softplan01',\n",
    "#     'localhost',\n",
    "#     '5432' ,\n",
    "#     'dictasstage'\n",
    "# ))\n",
    "\n",
    "# %env SCHEMA = dictasstage\n",
    "# operadora = 17\n",
    "\n",
    "# def load_to_db_append(df):\n",
    "#     df.to_sql('stg_op{}_{}'.format(operadora, tabela),\n",
    "#           con=engine,\n",
    "#           schema=os.getenv('SCHEMA'),\n",
    "#           if_exists='append',\n",
    "#           index=False,\n",
    "#           chunksize=10000,\n",
    "#           method='multi'\n",
    "#          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SCHEMA=dictas_stage\n"
     ]
    }
   ],
   "source": [
    "engine = create_engine('postgresql+psycopg2://{}:{}@{}:{}/{}'.format(\n",
    "    'etl_user',\n",
    "    'etl_user',\n",
    "    '172.27.13.6',\n",
    "    '5432' ,\n",
    "    'dictas'\n",
    "))\n",
    "\n",
    "%env SCHEMA = dictas_stage\n",
    "operadora = 17\n",
    "\n",
    "def load_to_db_append(df):\n",
    "    df.to_sql(tabela,\n",
    "          con=engine,\n",
    "          schema=os.getenv('SCHEMA'),\n",
    "          if_exists='append',\n",
    "          index=False,\n",
    "          chunksize=10000,\n",
    "          method='multi'\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(df, dict_rename, colunas):\n",
    "    # Ananalise das colunas que sobraram\n",
    "    colunas_sobraram = []\n",
    "    for item in dict_rename:\n",
    "        if dict_rename[item] == '':\n",
    "            colunas_sobraram.append(item)\n",
    "            # Remove coluna sobrante\n",
    "            df.drop(item, axis=1, inplace=True)  \n",
    "    if len(colunas_sobraram) > 0:\n",
    "        print('Sobraram as colunas:', colunas_sobraram)\n",
    "    \n",
    "    # Renomeando colunas\n",
    "    df.rename(inplace=True, columns=dict_rename)\n",
    "    \n",
    "    # Analise das colunas faltantes\n",
    "    colunas_faltantes = [value for value in colunas if not value in df.columns]\n",
    "    if len(colunas_faltantes) > 0:\n",
    "        print('Faltaram as colunas:', colunas_faltantes)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_strip_on_type_object(df):\n",
    "    for column in df:\n",
    "        if df[column].dtype == 'object':\n",
    "            df[column] = df[column].astype(str).str.strip()\n",
    "    return df\n",
    "\n",
    "def force_to_int(string):\n",
    "    try:\n",
    "        return int(string)\n",
    "    except ValueError:\n",
    "        return None\n",
    "    \n",
    "def transform_to_datetime(dt_in_string, date_format='%d/%m/%Y'):\n",
    "    if dt_in_string == '':\n",
    "        return None\n",
    "    else:\n",
    "        try:\n",
    "            df_in_datime = pd.to_datetime(dt_in_string, format=date_format)\n",
    "            return df_in_datime\n",
    "        except pd.errors.OutOfBoundsDatetime:\n",
    "            return None \n",
    "        \n",
    "def transform_ind_internacao(ind_internacao):\n",
    "    \"\"\"\n",
    "    Transform tipo_pessoa(string)\n",
    "    return bool or 2 (fora do padrão)\n",
    "    \"\"\"\n",
    "    if ind_internacao == 'NÃO':\n",
    "        return 'N'\n",
    "    elif ind_internacao == 'SIM':\n",
    "        return 'S'\n",
    "    else:\n",
    "        return 2        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/arlenwass/Projetos/Dictas/dados/cemig/2019-11-08/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns=50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bt_beneficiario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_path = os.path.join(path,'BENEFICIARIO.csv' )\n",
    "colunas = table_columns.bt_beneficiario\n",
    "df = pd.read_csv(file_path, sep='|', error_bad_lines=False, header = None, quoting=csv.QUOTE_NONE)\n",
    "\n",
    "dict_rename = {}\n",
    "for i in range(len(df.columns)):\n",
    "    dict_rename[df.columns[i]] =  colunas[i]\n",
    "\n",
    "df = rename_columns(df, dict_rename, colunas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index_to_drop = df.query('nr_beneficiario.astype(\"str\").str.contains(\"NULL\")').index\n",
    "df.iloc[index_to_drop].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[index_to_drop].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.dt_nascimento == '0001\\t'].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# bt_empresa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "file_path = os.path.join(path, 'EMPRESA.csv')\n",
    "colunas = table_columns.bt_empresa\n",
    "df = pd.read_csv(file_path, sep='|', error_bad_lines=False, header = None, quoting=csv.QUOTE_NONE, low_memory=False)\n",
    "\n",
    "dict_rename = {}\n",
    "for i in range(len(df.columns)):\n",
    "    dict_rename[df.columns[i]] =  colunas[i]\n",
    "\n",
    "df = rename_columns(df, dict_rename, colunas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df[df['pk_empresa'].duplicated(keep=False)].sort_values('pk_empresa').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# bt_medico_prestador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "file_path = os.path.join(path, 'PRESTADORES.csv')\n",
    "colunas = table_columns.bt_medico_prestador\n",
    "df = pd.read_csv(file_path, sep='|', error_bad_lines=False, header = None, quoting=csv.QUOTE_NONE, low_memory=False, na_values='NULL\\t')\n",
    "\n",
    "dict_rename = {}\n",
    "for i in range(len(df.columns)):\n",
    "    dict_rename[df.columns[i]] =  colunas[i]\n",
    "\n",
    "df = rename_columns(df, dict_rename, colunas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = df.drop_duplicates('pk_medico_prestador')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['dat_nascimento'] = df.dat_nascimento.str.replace('\\t', '')\n",
    "\n",
    "df['ano']= df.dat_nascimento.apply(lambda x: x[-4:] if x is not np.nan else x)\n",
    "\n",
    "df[df['ano'] == '9175']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bt_vidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(path, 'vidas')\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vidas_files = os.listdir(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colunas = table_columns.bt_vida\n",
    "df = pd.read_csv(os.path.join(file_path, vidas_files[0]), sep='|', error_bad_lines=False, encoding='utf8', header = None, quoting=csv.QUOTE_NONE, low_memory=False)\n",
    "\n",
    "dict_rename = {}\n",
    "for i in range(len(df.columns)):\n",
    "    dict_rename[df.columns[i]] =  colunas[i]\n",
    "\n",
    "df = rename_columns(df, dict_rename, colunas)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_sizes = []\n",
    "for table in vidas_files:\n",
    "    df = pd.read_csv(os.path.join(file_path, table), sep='|', error_bad_lines=False, encoding='utf8', header = None, quoting=csv.QUOTE_NONE, low_memory=False)\n",
    "    list_of_sizes.append(df.shape[0])\n",
    "    \n",
    "sum(list_of_sizes)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bt_custo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela = 'bt_custo'\n",
    "colunas = table_columns.bt_custo_cemig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files_path = os.path.join(path, 'Custos_atualizado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/arlenwass/Projetos/Dictas/dados/cemig/2019-11-08/Custos_atualizado/CUSTO 052017.csv\n",
      "/home/arlenwass/Projetos/Dictas/dados/cemig/2019-11-08/Custos_atualizado/CUSTO 062019.csv\n",
      "/home/arlenwass/Projetos/Dictas/dados/cemig/2019-11-08/Custos_atualizado/CUSTO 022019.csv\n",
      "/home/arlenwass/Projetos/Dictas/dados/cemig/2019-11-08/Custos_atualizado/CUSTO 022018.csv\n",
      "/home/arlenwass/Projetos/Dictas/dados/cemig/2019-11-08/Custos_atualizado/CUSTO 072017.csv\n",
      "/home/arlenwass/Projetos/Dictas/dados/cemig/2019-11-08/Custos_atualizado/CUSTO 052018.csv\n",
      "/home/arlenwass/Projetos/Dictas/dados/cemig/2019-11-08/Custos_atualizado/CUSTO 042018.csv\n",
      "/home/arlenwass/Projetos/Dictas/dados/cemig/2019-11-08/Custos_atualizado/CUSTO 082019.csv\n",
      "/home/arlenwass/Projetos/Dictas/dados/cemig/2019-11-08/Custos_atualizado/CUSTO 012018.csv\n",
      "/home/arlenwass/Projetos/Dictas/dados/cemig/2019-11-08/Custos_atualizado/CUSTO 032019.csv\n",
      "/home/arlenwass/Projetos/Dictas/dados/cemig/2019-11-08/Custos_atualizado/CUSTO 092019.csv\n",
      "/home/arlenwass/Projetos/Dictas/dados/cemig/2019-11-08/Custos_atualizado/CUSTO 032018.csv\n",
      "/home/arlenwass/Projetos/Dictas/dados/cemig/2019-11-08/Custos_atualizado/CUSTO 042019.csv\n",
      "/home/arlenwass/Projetos/Dictas/dados/cemig/2019-11-08/Custos_atualizado/CUSTO 082018.csv\n",
      "/home/arlenwass/Projetos/Dictas/dados/cemig/2019-11-08/Custos_atualizado/CUSTO 022017.csv\n",
      "/home/arlenwass/Projetos/Dictas/dados/cemig/2019-11-08/Custos_atualizado/CUSTO 062018.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 54626: expected 32 fields, saw 33\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/arlenwass/Projetos/Dictas/dados/cemig/2019-11-08/Custos_atualizado/CUSTO 072019.csv\n",
      "/home/arlenwass/Projetos/Dictas/dados/cemig/2019-11-08/Custos_atualizado/CUSTO 062017.csv\n",
      "/home/arlenwass/Projetos/Dictas/dados/cemig/2019-11-08/Custos_atualizado/CUSTO 042017.csv\n",
      "/home/arlenwass/Projetos/Dictas/dados/cemig/2019-11-08/Custos_atualizado/CUSTO 032017.csv\n",
      "/home/arlenwass/Projetos/Dictas/dados/cemig/2019-11-08/Custos_atualizado/CUSTO 052019.csv\n",
      "/home/arlenwass/Projetos/Dictas/dados/cemig/2019-11-08/Custos_atualizado/CUSTO 072018.csv\n",
      "/home/arlenwass/Projetos/Dictas/dados/cemig/2019-11-08/Custos_atualizado/CUSTO 012019.csv\n",
      "/home/arlenwass/Projetos/Dictas/dados/cemig/2019-11-08/Custos_atualizado/CUSTO 082017.csv\n",
      "/home/arlenwass/Projetos/Dictas/dados/cemig/2019-11-08/Custos_atualizado/CUSTO 092018.csv\n",
      "/home/arlenwass/Projetos/Dictas/dados/cemig/2019-11-08/Custos_atualizado/CUSTO 092017.csv\n"
     ]
    }
   ],
   "source": [
    "for a in os.listdir(files_path):\n",
    "    file = os.path.join(files_path, a)\n",
    "    print(file)\n",
    "    df = pd.read_csv(file, sep='|', encoding='utf8', header=None, error_bad_lines=False,\n",
    "            quoting=csv.QUOTE_NONE, na_values='NULL\\t')\n",
    "\n",
    "    dict_rename = {}\n",
    "    for i in range(len(df.columns)):\n",
    "        dict_rename[df.columns[i]] =  colunas[i]\n",
    "\n",
    "    df = rename_columns(df, dict_rename, colunas)\n",
    "    df = apply_strip_on_type_object(df)\n",
    "    df['ind_internacao'] = df.ind_internacao.apply(transform_ind_internacao)\n",
    "    df['cod_medicoexecutante'] = df.cod_medicoexecutante.apply(force_to_int)\n",
    "    df['cod_medicosolicitante'] = df.cod_medicosolicitante.apply(force_to_int)\n",
    "\n",
    "    df = df.query('dt_realizacao != \"/  /\"')\n",
    "\n",
    "    df['mes_competencia'] = df.mes_competencia.astype(str).str.rjust(6, '0')\n",
    "    df['mes_competencia'] = df.mes_competencia.apply(transform_to_datetime, args=('%m%Y',))\n",
    "\n",
    "    df['vl_co'] = df.vl_co.fillna(0)\n",
    "    df['vl_hm'] = df.vl_hm.fillna(0)\n",
    "    df['vl_filme'] = df.vl_filme.fillna(0)\n",
    "    df['vl_total'] = df.vl_total.fillna(0)\n",
    "    \n",
    "    df['dt_realizacao'] = df.dt_realizacao.apply(transform_to_datetime)\n",
    "    df['dt_ini_internacao'] = df.dt_ini_internacao.apply(transform_to_datetime)\n",
    "    df['dt_fim_internacao'] = df.dt_fim_internacao.apply(transform_to_datetime)\n",
    "\n",
    "    df['cod_operadora'] = 17\n",
    "\n",
    "    load_to_db_append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shapes = []\n",
    "for a in os.listdir(files_path):\n",
    "    file = os.path.join(files_path, a)\n",
    "    df = pd.read_csv(file, sep='|', encoding='utf8', header=None, error_bad_lines=False,\n",
    "            quoting=csv.QUOTE_NONE, na_values='NULL\\t')\n",
    "    shapes.append(df.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acabou\n"
     ]
    }
   ],
   "source": [
    "print('acabou')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.listdir(files_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bt_servico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(path, 'SERVICOS.csv')\n",
    "colunas = table_columns.bt_servico\n",
    "df = pd.read_csv(file_path, sep='|', error_bad_lines=False, encoding='utf8', header = None, quoting=csv.QUOTE_NONE, low_memory=False)\n",
    "\n",
    "dict_rename = {}\n",
    "for i in range(len(df.columns)):\n",
    "    dict_rename[df.columns[i]] =  colunas[i]\n",
    "\n",
    "df = rename_columns(df, dict_rename, colunas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bt_consultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(path,'CONSULTAS.csv' )\n",
    "colunas = table_columns.bt_consulta\n",
    "df = pd.read_csv(file_path, sep='|', error_bad_lines=False, header = None, quoting=csv.QUOTE_NONE)\n",
    "\n",
    "dict_rename = {}\n",
    "for i in range(len(df.columns)):\n",
    "    dict_rename[df.columns[i]] =  colunas[i]\n",
    "\n",
    "df = rename_columns(df, dict_rename, colunas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bt_diarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_path = os.path.join(path, 'DIARIAS.csv')\n",
    "colunas = table_columns.bt_diaria\n",
    "df = pd.read_csv(file_path, sep='|', error_bad_lines=False, header = None, quoting=csv.QUOTE_NONE, low_memory=False)\n",
    "\n",
    "dict_rename = {}\n",
    "for i in range(len(df.columns)):\n",
    "    dict_rename[df.columns[i]] =  colunas[i]\n",
    "\n",
    "df = rename_columns(df, dict_rename, colunas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
